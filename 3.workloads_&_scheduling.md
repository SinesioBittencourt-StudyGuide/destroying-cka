# Workloads & Scheduling

## 1. Understand deployments and how to perform rolling update and rollbacks

Deployment required Fields:

- apiVersion
- kind
- metadata
- spec

The deployment ensures that only a certain number of pods be available while the other are updating. The maxUnavailable config field take cares of defyining the minimum number of pods that need to be up during pods update, it is calculated in percentage(%).

The deployment also garantees the maximum number of pods that can be created over the maximum capacity, the maxAvailable field defines the maximum percentage of pods that can outline the total number of desired pods.

Rollback and rollout a deployment steps :

Define a deployment in the imperative way:

```bash
kubectl create deployment --image=nginx
```

Define a pod in declarative way(using a file):

```bash
kubectl create -f <yaml_file>
```

Check the rollout status of the pods:

```bash
kubectl rollout status deployment/nginx-deployment
```

Get ReplicationControllers(Deployments are the best practice for deploying pods):

```bash
kubectl get rc
```

Check the running pods:

```bash
kubectl get pods
```

Check deployment information:

```bash
kubectl describe deployments
```

Check the rollout history(all releases) of a deployment:

```bash
kubectl rollout history deployment.v1.apps/nginx-deployment
```

Create a annotation for the deployment, usefull for identification and organization:

```bash
kubectl annotate deployment.v1.apps/nginx-deployment kubernetes.io/change-cause="some nice message here"
```

Check rollout information for a specific revision:

```bash
kubectl rollout history deployment.v1.apps/nginx-deployment --revision=2
```

Perform a Rollback:

```bash
kubectl rollout undo deployment.v1.apps/nginx-deployment --to-revision=2
```

Check deployment status:

```bash
kubectl describe deployment nginx-deployment
```

References:

[Performing a Rolling Update](https://kubernetes.io/docs/tutorials/kubernetes-basics/update/update-intro/)

[Perform a Rollback on a DaemonSet](https://kubernetes.io/docs/tasks/manage-daemon/rollback-daemon-set/)

## 2. Use ConfigMaps and Secrets to configure applications

ConfigMaps and Secrets are about decoupling data from the Pod that needs them.

- ConfigMaps are clear-text, Secrets are base64 encoded.
- Different types can be used:
    1. Files
    2. Directories
    3. Literals(Variables)
- All associated data is stored in the ConfigMap or Secret object.
- Secrets are mainly used to push variables.
- Secrets are used by the k8s cluster itself in order to connect k8s components to one another.

Create a ConfigMap:

```bash
kubectl create cm myconfig --from-literal=color=red
```

Create a Secret:

```bash
kubectl create secret generic secretstuff --from-literal=password=password --from-literal=user=linda
```

Retrieve Secret information:

```bash
kubectl get secrets secretstuff -o yaml
```

References:

[Secrets](https://kubernetes.io/docs/concepts/configuration/secret/)

[ConfigMaps](https://kubernetes.io/docs/concepts/configuration/configmap/)

## Know how to scale applications

### Scaling Deployments

For scaling deployment you can do it using the 'scale' command:

```bash
kubectl scale deployment.v1.apps/nginx-deployment --replicas=10
```

Or using the 'edit' command and change the replicas field, after saving the changes will be applyed:

```bash
kubectl edit deployment <deployment name>
```

### Scaling StatefulSets

Retrieve StatefulSets information:

```bash
kubectl get statefulsets <stateful-set-name>
```

Scale StatefulSets using 'scale':

```bash
kubectl scale statefulsets <stateful-set-name> --replicas=<new-replicas>
```

You can also change the yaml/json file and use the apply command to make changes to the deployed StatefulSet:

```bash
kubectl apply -f <stateful-set-file-updated>
```

Using 'edit' also is possible:

```bash
kubectl edit statefulsets <stateful-set-name>
```

And there is also a patch command for patching updates to the Object:

```bash
kubectl patch statefulsets <stateful-set-name> -p '{"spec":{"replicas":<new-replicas>}}'
```

### Horizontal Pod Autoscaler

Scales the number of Pods based on CPU utilization. Only applied to objects that can be scaled. Implemented as a Kubernetes API resource and a controller.

Retrieve HPA condition information:

```bash
kubectl get hpa
```

Detailed information about HPA:

```bash
kubectl describe hpa
```

Define an autoscale plan for a ReplicaSet, it defines when the pods should be restarted, the minimum pods that need to be running during the rollout and the maximum number of pods that can be created:

```bash
kubectl autoscale replicaset foo --min=2 --max=5 --cpu-percent=80
```

References:

[Running Multiple Instances of Your App](https://kubernetes.io/docs/tutorials/kubernetes-basics/scale/scale-intro/)

[Horizontal Pod Autoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)

[Scale a StatefulSet](https://kubernetes.io/docs/tasks/run-application/scale-stateful-set/)

## 3. Understand the primitives used to create robust, self- healing, application deployments

### Deployment

It is a Controller that manages the states of Pods and ReplicaSets. It provides flexibility when it comes to updating and managing those resources. Deployments are **declarative updates for Pods and ReplicaSets**. You describe a *desired state* and the deployment work it's way to change to that state.

Common use cases for deployments:

- Create a Deployment to rollout a ReplicaSet
- Declare the new state of the Pods
- Rollback to an earlier Deployment revision
- Scale up the Deployment to facilitate more load
- Pause the Deployment
- Use the status of the Deployment
- Clean up older ReplicaSets

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx # refers to the 
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx # refers to pods in the replicas
  template:
    metadata:
      labels:
        app: nginx # pods that will be created 
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

Deployment required Fields

- apiVersion
- kind
- metadata
- spec

Deploying a Deployment from a YAML file:

```bash
kubectl create -f [file]
```

Retrieve deployments running on the cluster:

```bash
kubectl get deployments
```

Check pods running in the deployment:

```bash
kubectl get pods --show-labels
```

Using 'set' command to change the image version:

```bash
kubectl set image deployment/nginx-deployment nginx=nginx:1.16.1 --record
```

Using 'edit'to change deployment image version:

```bash
kubectl edit deployment.v1.apps/nginx-deployment

```

Retrieve deployment information:

```bash
kubectl describe deployments
```

Deployment ensures that only a certain number of Pods are down while they are being updated. By default, it ensures that at least 75% of the desired number of Pods are up (25% max unavailable).

Deployment also ensures that only a certain number of Pods are created above the desired number of Pods. By default, it ensures that at most 125% of the desired number of Pods are up (25% max surge).

### ReplicaSet

Orchestrates the individual lifecycle of Pods and updates.

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # modify replicas according to your case
  replicas: 3
  selector:
    matchLabels:
      tier: frontend
  template:
    metadata:
      labels:
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google_samples/gb-frontend:v3
```

### DaemonSet

The controller ensures that a single pod, of the same type, runs on every node in the cluster.
A DaemonSet ensures that all (or some) Nodes run a copy of a Pod. As nodes are added to the cluster, Pods are added to them. As nodes are removed from the cluster, those Pods are garbage collected. Deleting a DaemonSet will clean up the Pods it created.

### StatefulSet

In order to track each Pod as a unique object, the controllers uses an identity composed of stable storage, stable network identity, and an ordinal. This identity remains with the node, regardless of which node the Pod is running on at any one time.

References:

[Deployments](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)

[ReplicaSet](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/)

[DaemonSet](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/)

[StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/)

## 4. Understand how resource limits can affect Pod scheduling

When the kubelet starts a Container of a Pod, it passes the CPU and memory limits to the container runtime.

If a Container exceeds its memory limit, it might be terminated. If it is restartable, the kubelet will restart it, as with any other type of runtime failure.

If a Container exceeds its memory request, it is likely that its Pod will be evicted whenever the node runs out of memory.

A Container might or might not be allowed to exceed its CPU limit for extended periods of time. However, it will not be killed for excessive CPU usage.

Reference:

[Managining Resources for Containers](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers)
[How Pods with resource limits are run](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#how-pods-with-resource-requests-are-scheduled)
[Kubernetes Scheduler](https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/)

## 5. Awareness of manifest management and common templating tools

### Organizing resource configurations

Using labels effectively

```bash
kubectl get pods -Lapp -Ltier -Lrole
```

```bash
kubectl get pods -lapp=guestbook,role=slave
```

```bash
kubectl get pods -lapp=guestbook,role=slave
```

```bash
kubectl label pods -l app=nginx tier=fe
```

```bash
kubectl get pods -l app=nginx -L tier
```

### Updating annotations

Sometimes you would want to attach annotations to resources. Annotations are arbitrary non-identifying metadata for retrieval by API clients such as tools, libraries, etc. This can be done with kubectl annotate. For example:

```bash
kubectl annotate pods my-nginx-v4-9gw19 description='my frontend running nginx'
```

### Scaling your application

Scale an Object directly:

```bash
kubectl scale deployment/my-nginx --replicas=1
```

```bash
kubectl autoscale deployment/my-nginx --min=1 --max=3
```

### In-place updates of resources

Sometimes it's necessary to make narrow, non-disruptive updates to resources you've created.

```bash
kubectl apply 
kubectl edit 
kubectl patch
```

### Disruptive updates

In some cases, you may need to update resource fields that cannot be updated once initialized, or you may want to make a recursive change immediately, such as to fix broken pods created by a Deployment. To change such fields, use replace --force, which deletes and re-creates the resource. In this case, you can modify your original configuration file:

```bash
kubectl get deployment my-nginx -o yaml > /tmp/nginx.yaml
```

```bash
kubectl replace -f <file> --force
```

Do some edit, and then save the file:

```bash
kubectl apply -f /tmp/nginx.yaml
```

References:

[Managing Resources](https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/)
