# Services & Networking

## 1. Understand host networking configuration on the cluster nodes

### Understanding Cluster Networking

Kubernetes relies on the Container Network Interface, CNI, Project to comply with the following requirements:

- All containers must communicate with each without NAT.

- Nodes can communicate with containers without NAT.

A container’s IP address is the same it sees itself as the outside the container.
Pods themselves are ephemeral
Local disk state, node scheduling, and IP addresses will all be replaced regularly during a pod’s life cycle.

A pod has a unique IP address, which is shared by all containers in the pod. The primary motivation behind giving every pod an IP address is to remove constraints around port numbers.
Kubernetes chose the IP per pod model to be more comfortable for developers to adopt and be easier to run third party workloads. Unfortunately for us, allocating and routing an IP address for every pod adds substantial complexity to a Kubernetes cluster.

The Kubernetes Network Is Default-OpenBy default, Kubernetes will allow any traffic to or from any pod.This passive connectivity means, among other things,that any pod in a cluster can connect to any other pod in that same cluster.That can easily lead to abuse,especially if services do not use authentication or if an attacker obtains credentials.

When explicitly creating a pod, it is possible to specify the IP address. StatefulSets are a built-in workloadtype intended for workloads such as databases, which maintain a pod identity concept and give a new pod the same nameand IP address as the pod it replaces.

Every Kubernetes Node runs a component called the kubelet, which manages pods on the node. The networking functionality in the kubelet comes from API interactions with a CNI plugin on the node.

The CNI plugin is what manages pod IP addresses and individual container network provisioning.

Kubernetes does not ship with a default CNI plugin, which means that in a standard installation of Kubernetes, pods cannot use the network.

### Node and Pod Network Layout

- Group of IP addresses for Pods
- Nodes and Pods must have L3 connectivity in the IP Address space.
- There are broadly three approaches, with many variations, to structuring a cluster’s network: isolated, flat, and island networks.

#### Isolated Networks

- Nodes are routable on the broader network.
- Pods cannot reach other pods(or any other hosts) outside the cluster.
- Multiple clusters can use the same IP Address space.
- Secure cluster option, isolated cluster.

#### Flat Networks

- All pods have an IP address that is routable from the broader network
- Pods can connect directly to arbitrary hosts in the network.
- Any host on the network is reachable to and from any pod.

#### Island Networks

- Island cluster networks are, at a high level, a combination of isolated and flat networks.
- Traffic to and from pods must pass through some form of proxy, as the pod’s IP address is not reachable externally
- In other words, packets appear to be “from” the node, rather than the pod.

### Pod Readiness and Probes

kubelet dictates Pod readiness with a user-specified readiness probe.
kubelet can also perform two types of health checks for individual containers in a pod: liveliness probes and readiness probes

#### Liveness Probes

- Pod spec defines the specific liveliness probes to inform the kubelet of the pod's health
- If the probe fails more than the failureThreshold number of times, the kubelet will terminate and restart that container.
- Let the kubelet know when to restart a container.
- When pods use them, they only depend on the container they are testing, with no other dependencies
- Used in specific health check endpoints, which provide minimal validation of criteria.

#### Readiness probes

- Pod Readiness is an additional indication of whether the pod is ready to serve traffic.
- User-specified readiness probes dictates Pod Readiness.
- Determines whether pod address shows up in the endpoints object from an external source.
- Determine when the application inside the container is ready.
- readinessGates specify a list of additional conditions that the kubelet evaluates for Pod readiness.
- conditionType attribute is a condition in the pod's condition list with a matching type.
- When a container's readiness probe fails too many times, the kubelet writes the failure to the pod's status, it doesn't terminate it.

#### startupProbe

- Will inform the kubelet whether the application inside the container is started.
- Takes precedent over the others
- If a startupProbe is defined int he pod spec all other probes are disabled

### CNI

- Network Plugin in Kubelet that enables networking to get IPs for Pods and Services.

### gRPC

- API to communicate API Server to ETCD, Controller Manager, and Scheduler

### CRI(Container Runtime Interface)

gRPC API compiled in kubelet, allowing kubelet to talk to container runtimes using gRPC API. The Container Runtime provider must adapt it to CRI API to allow kubelet to talk to them using OCI Standard (runc). CRI consists of protocol buffers and gRPC API, and libraries.

- Protocol buffers
- gRPC API
- libraries

### CNI Specification

There are four operations that a CNI plugin must support:

- ADD - add a container to the network
- DEL - delete a container from the network
- CHECK - return an error if ther eis a problem with the container's network
- VERSION - report a version information about the plugin

CNI plugin operations are invoked using binaries, Kubernetes supplies any configuration for the command in JSON to stdin, and recieves the command's output in JSON through stdout.

#### CNI Plugins

CNI Plugins has two primary responsibilities

- Allocate and assign unique IP Addresses for Pods
- Ensure that routes exist within Kubernetes to each pod IP address.

By default, kubelet reads CNI configuration from the directory /etc/cni/net.d/ and expects to find the CNI binary in /opt/cni/bin/

There are two broad categories of CNI network models:

- Flat networks - the CNI driver uses IP addresses from the cluster’s network, which typically requires many IP addresses to be available to the cluste
- Overlay networks -  the CNI driver creates a secondary network within Kubernetes, which uses the cluster’s network (called the underlay network) to send packets(tunneling).

#### The IPAM Interface

The CNI spec has a second interface, the IP Address Management (IPAM) interface, to reduce duplication of IP allocation code in CNI plugins. The IPAM plugin must determine and output the interface IP address, gateway, and routes as seen in Example 4.2. The IPAM interface is similar to the CNI: a binary with JSON input to stdin and JSON output from stdout.

```bash
{
  "cniVersion": "0.4.0",
  "ips": [
      {
          "version": "<4-or-6>",
          "address": "<ip-and-prefix-in-CIDR>",
          "gateway": "<ip-address-of-the-gateway>"  (optional)
      },
      ...
  ],
  "routes": [                                       (optional)
      {
          "dst": "<ip-and-prefix-in-cidr>",
          "gw": "<ip-of-next-hop>"                  (optional)
      },
      ...
  ]
  "dns": {                                          (optional)
    "nameservers": <list-of-nameservers>            (optional)
    "domain": <name-of-local-domain>                (optional)
    "search": <list-of-search-domains>              (optional)
    "options": <list-of-options>                    (optional)
  }
}
```

### NetworkPolicy

- NetworkPolicy is a resource type in Kubernetes, which contains allow-based firewall rules.
- Users can add NetworkPolicy objects to restrict connections to and from pods.
- The NetworkPolicy resource acts as a configuration for CNI plugins.
- NetworkPolicy object contains a pod selector, ingress rules, and egress rules.
- The policy will apply to all pods in the same namespace as the NetworkPolicy that match the selector label.

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: demo
  namespace: default
spec:
  podSelector:
    matchLabels:
      app: demo
  policyTypes:
  - Ingress
  - Egress
  ingress: []NetworkPolicyIngressRule # Not expanded
  egress: []NetworkPolicyEgressRule # Not expanded
```

NetworkPolicy rules act as exceptions, “allow list,” to the default-block caused by selecting pods in a policy.

References:

[Networking](https://kubernetes.io/docs/concepts/cluster-administration/networking/)

## 2. Understand connectivity between Pods

References:

[Pod Networking](https://kubernetes.io/docs/concepts/workloads/pods/#pod-networking)

## 3. Understand ClusterIP, NodePort, LoadBalancer service types and endpoints

References:

[Service Resource](https://kubernetes.io/docs/concepts/services-networking/service/#service-resource)

## 4. Know how to use Ingress controllers and Ingress resources

Ingress

- Ingress exposes HTTP and HTTPS routes from outside the cluster to services within the cluster
- For non-HTTP and HTTPS-based traffic, the LoadBalancer or NodePort service objects must be used
- Advanced traffic routing can be controlled by Ingress rules
- In the easiest configuration, Ingress forwards all traffic to one service
- Paths can be used to forward traffic to multiple services
- ingress is a loadbalancer on top of a loadbalancer
- on top of ingress there's ingress controller, forward http/https traffic to ingress
- 


References:

[Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/)
[Ingress Controllers](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/)

## 5. Know how to configure and use CoreDNS

References:

[Using CoreDNS for Service Discovery](https://kubernetes.io/docs/tasks/administer-cluster/coredns/)

## 6. Choose an appropriate container network interface plugin

### CNI Plugin Options

#### Cilium

Cilium is L7/HTTP aware CNI and can enforce network policies on L3-L7 using an identity-based security model decoupled from the network addressing.(Uses eBPF technology).

#### Flannel

Focuses on network, and is simple and easy way to configure a layer three network fabric designed for Kubernetes.

#### Calico

Calico configures a layer three network that uses the BGP routing protocol to route packets between hosts. Can also integrate with Istio, to interpret and enforce policy for workloads within the cluster at the service mush and network infrastructure layers.



References:

[Network Plugins](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/)