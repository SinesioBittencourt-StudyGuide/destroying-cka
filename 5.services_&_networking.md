# Services & Networking

## Summary

* [Services &amp; Networking](#services--networking)
   * [Summary](#summary)
   * [1. Understand host networking configuration on the cluster nodes](#1-understand-host-networking-configuration-on-the-cluster-nodes)
      * [Understanding Cluster Networking](#understanding-cluster-networking)
      * [Node and Pod Network Layout](#node-and-pod-network-layout)
         * [Isolated Networks](#isolated-networks)
         * [Flat Networks](#flat-networks)
         * [Island Networks](#island-networks)
      * [Pod Readiness and Probes](#pod-readiness-and-probes)
         * [Liveness Probes](#liveness-probes)
         * [Readiness probes](#readiness-probes)
         * [startupProbe](#startupprobe)
      * [CNI](#cni)
      * [gRPC](#grpc)
      * [CRI(Container Runtime Interface)](#cricontainer-runtime-interface)
      * [CNI Specification](#cni-specification)
         * [CNI Plugins](#cni-plugins)
         * [The IPAM Interface](#the-ipam-interface)
      * [NetworkPolicy](#networkpolicy)
   * [2. Understand connectivity between Pods](#2-understand-connectivity-between-pods)
      * [Pause Containers and Pod Networking Internals](#pause-containers-and-pod-networking-internals)
      * [Pod-to-Pod Communication](#pod-to-pod-communication)
      * [NetworkPolicies](#networkpolicies)
   * [3. Understand ClusterIP, NodePort, LoadBalancer service types and endpoints](#3-understand-clusterip-nodeport-loadbalancer-service-types-and-endpoints)
      * [Services](#services)
   * [4. Know how to use Ingress controllers and Ingress resources](#4-know-how-to-use-ingress-controllers-and-ingress-resources)
   * [5. Know how to configure and use CoreDNS](#5-know-how-to-configure-and-use-coredns)
   * [6. Choose an appropriate container network interface plugin](#6-choose-an-appropriate-container-network-interface-plugin)
      * [CNI Plugin Options](#cni-plugin-options)
         * [Cilium](#cilium)
         * [Flannel](#flannel)
         * [Calico](#calico)

## 1. Understand host networking configuration on the cluster nodes

### Understanding Cluster Networking

Kubernetes relies on the Container Network Interface, CNI, Project to comply with the following requirements:

- All containers must communicate with each other without NAT.

- Nodes can communicate with containers without NAT.

A container’s IP address is the same it sees itself as the outside the container.
Pods themselves are ephemeral
Local disk state, node scheduling, and IP addresses will all be replaced regularly during a pod’s life cycle.

A pod has a unique IP address, which is shared by all containers in the pod. The primary motivation behind giving every pod an IP address is to remove constraints around port numbers.
Kubernetes chose the IP per pod model to be more comfortable for developers to adopt and be easier to run third party workloads. Unfortunately for us, allocating and routing an IP address for every pod adds substantial complexity to a Kubernetes cluster.

The Kubernetes Network Is Default-OpenBy default, Kubernetes will allow any traffic to or from any pod.This passive connectivity means, among other things,that any pod in a cluster can connect to any other pod in that same cluster.That can easily lead to abuse,especially if services do not use authentication or if an attacker obtains credentials.

When explicitly creating a pod, it is possible to specify the IP address. StatefulSets are a built-in workloadtype intended for workloads such as databases, which maintain a pod identity concept and give a new pod the same nameand IP address as the pod it replaces.

Every Kubernetes Node runs a component called the kubelet, which manages pods on the node. The networking functionality in the kubelet comes from API interactions with a CNI plugin on the node.

The CNI plugin is what manages pod IP addresses and individual container network provisioning.

Kubernetes does not ship with a default CNI plugin, which means that in a standard installation of Kubernetes, pods cannot use the network.

### Node and Pod Network Layout

- Group of IP addresses for Pods
- Nodes and Pods must have L3 connectivity in the IP Address space.
- There are broadly three approaches, with many variations, to structuring a cluster’s network: isolated, flat, and island networks.

#### Isolated Networks

- Nodes are routable on the broader network.
- Pods cannot reach other pods(or any other hosts) outside the cluster.
- Multiple clusters can use the same IP Address space.
- Secure cluster option, isolated cluster.

#### Flat Networks

- All pods have an IP address that is routable from the broader network
- Pods can connect directly to arbitrary hosts in the network.
- Any host on the network is reachable to and from any pod.

#### Island Networks

- Island cluster networks are, at a high level, a combination of isolated and flat networks.
- Traffic to and from pods must pass through some form of proxy, as the pod’s IP address is not reachable externally
- In other words, packets appear to be “from” the node, rather than the pod.

### Pod Readiness and Probes

kubelet dictates Pod readiness with a user-specified readiness probe.
kubelet can also perform two types of health checks for individual containers in a pod: liveliness probes and readiness probes

#### Liveness Probes

- Pod spec defines the specific liveliness probes to inform the kubelet of the pod's health
- If the probe fails more than the failureThreshold number of times, the kubelet will terminate and restart that container.
- Let the kubelet know when to restart a container.
- When pods use them, they only depend on the container they are testing, with no other dependencies
- Used in specific health check endpoints, which provide minimal validation of criteria.

#### Readiness probes

- Pod Readiness is an additional indication of whether the pod is ready to serve traffic.
- User-specified readiness probes dictates Pod Readiness.
- Determines whether pod address shows up in the endpoints object from an external source.
- Determine when the application inside the container is ready.
- readinessGates specify a list of additional conditions that the kubelet evaluates for Pod readiness.
- conditionType attribute is a condition in the pod's condition list with a matching type.
- When a container's readiness probe fails too many times, the kubelet writes the failure to the pod's status, it doesn't terminate it.

#### startupProbe

- Will inform the kubelet whether the application inside the container is started.
- Takes precedent over the others
- If a startupProbe is defined int he pod spec all other probes are disabled

### CNI

- Network Plugin in Kubelet that enables networking to get IPs for Pods and Services.

### gRPC

- API to communicate API Server to ETCD, Controller Manager, and Scheduler

### CRI(Container Runtime Interface)

gRPC API compiled in kubelet, allowing kubelet to talk to container runtimes using gRPC API. The Container Runtime provider must adapt it to CRI API to allow kubelet to talk to them using OCI Standard (runc). CRI consists of protocol buffers and gRPC API, and libraries.

- Protocol buffers
- gRPC API
- libraries

### CNI Specification

There are four operations that a CNI plugin must support:

- ADD - add a container to the network
- DEL - delete a container from the network
- CHECK - return an error if ther eis a problem with the container's network
- VERSION - report a version information about the plugin

CNI plugin operations are invoked using binaries, Kubernetes supplies any configuration for the command in JSON to stdin, and recieves the command's output in JSON through stdout.

#### CNI Plugins

CNI Plugins has two primary responsibilities

- Allocate and assign unique IP Addresses for Pods
- Ensure that routes exist within Kubernetes to each pod IP address.

By default, kubelet reads CNI configuration from the directory /etc/cni/net.d/ and expects to find the CNI binary in /opt/cni/bin/

There are two broad categories of CNI network models:

- Flat networks - the CNI driver uses IP addresses from the cluster’s network, which typically requires many IP addresses to be available to the cluste
- Overlay networks -  the CNI driver creates a secondary network within Kubernetes, which uses the cluster’s network (called the underlay network) to send packets(tunneling).

#### The IPAM Interface

The CNI spec has a second interface, the IP Address Management (IPAM) interface, to reduce duplication of IP allocation code in CNI plugins. The IPAM plugin must determine and output the interface IP address, gateway, and routes as seen in Example 4.2. The IPAM interface is similar to the CNI: a binary with JSON input to stdin and JSON output from stdout.

```bash
{
  "cniVersion": "0.4.0",
  "ips": [
      {
          "version": "<4-or-6>",
          "address": "<ip-and-prefix-in-CIDR>",
          "gateway": "<ip-address-of-the-gateway>"  (optional)
      },
      ...
  ],
  "routes": [                                       (optional)
      {
          "dst": "<ip-and-prefix-in-cidr>",
          "gw": "<ip-of-next-hop>"                  (optional)
      },
      ...
  ]
  "dns": {                                          (optional)
    "nameservers": <list-of-nameservers>            (optional)
    "domain": <name-of-local-domain>                (optional)
    "search": <list-of-search-domains>              (optional)
    "options": <list-of-options>                    (optional)
  }
}
```

### NetworkPolicy

- NetworkPolicy is a resource type in Kubernetes, which contains allow-based firewall rules.
- Users can add NetworkPolicy objects to restrict connections to and from pods.
- The NetworkPolicy resource acts as a configuration for CNI plugins.
- NetworkPolicy object contains a pod selector, ingress rules, and egress rules.
- The policy will apply to all pods in the same namespace as the NetworkPolicy that match the selector label.

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: demo
  namespace: default
spec:
  podSelector:
    matchLabels:
      app: demo
  policyTypes:
  - Ingress
  - Egress
  ingress: []NetworkPolicyIngressRule # Not expanded
  egress: []NetworkPolicyEgressRule # Not expanded
```

NetworkPolicy rules act as exceptions, “allow list,” to the default-block caused by selecting pods in a policy.

References:

[Networking](https://kubernetes.io/docs/concepts/cluster-administration/networking/)

## 2. Understand connectivity between Pods

### Pause Containers and Pod Networking Internals

Inside the Pod there is a Pause Container, the pause container is responsible for managing the IP address for the Pod itself and for internal containers in the Pod. Containers in a Pod can communicate with each other using standard inter-process communications (SystemV, POSIX).

Normally the Pod has only one container, but in case there is two or more, we need solutions for stablishing the communication between then, because at the end is the same IP address. Some solutions are:

- IPC(Inter-process communication)
- Shared Volume
- loopback

To get information about networking in containers we can deploy a Pod and check it:

By deploying two containers on the same Pod, both of the containers will have the same IP Address:

```yaml
kind: Pod
metadata:
  name: net-demo
spec:
  containers:
  - name: busy1
    image: busybox
    command:
    - sleep
    - "3600"
  - name: busy2
    image: busybox
    command:
    - sleep
    - "3600"
```

We can check this by executing the command:

```bash
kubectl exec net-demo -c busy1 -- ip a s

kubectl exec net-demo -c busy2 -- ip a s
```

To check the Pause container created on the Pod we can do this by finding which node is running the Pod:

```bash
kubectl get po -o wide
```

SSH into the node and checking it using Docker(or the Container Runtime Interface equivalent command):

```bash
docker ps | grep pause | grep <pod-name>
```

### Pod-to-Pod Communication

Pods are deployed in one big network, and they are assigend a unique IP Address. Pods are accessible on their specific network. Any Pod can communicate directly with one another and are all in the same network namespace. The CNI provides a framework in which networking modules can be used to establish communication according to different needs. Inter-Pod container communication can be acomplished using IP.

To check this inter-pod communication we can check a Pod IP Address:

```bash
kubectl get pods -o wide
```

We can execute a shell into a container and ping any other Pod IP in the Cluster:

```bash
kubectl exec <pod-name>  -- ping <some-other-pod-ip-address>
```

We can stablish restrictions to connections in the network, for this we use NetworkPolicies.

### NetworkPolicies

NetworkPolicies make it possible to implement restrictions on direct traffic between Pods.
Using NetworkPolicies


In the container the service is running on port 80, and the Pod is exposing the service on port 9377 on the pod

References:

[Pod Networking](https://kubernetes.io/docs/concepts/workloads/pods/#pod-networking)
[Network Policies](https://kubernetes.io/docs/concepts/services-networking/network-policies/)

## 3. Understand ClusterIP, NodePort, LoadBalancer service types and endpoints

### Services

In the container the service is running on port 80, and the Pod is exposing the service on port 9377 on the pod

References:

[Service Resource](https://kubernetes.io/docs/concepts/services-networking/service/#service-resource)

## 4. Know how to use Ingress controllers and Ingress resources

Ingress exposes HTTP and HTTPS routes from outside the cluster to services within the cluster. This may require a Ingress Controller, that sits on top of Ingress.

The Ingress Controller makes the connection between the **external physical** network and the **internal** **cluster** network.

Some features of Ingress:

- Ingress exposes HTTP and HTTPS routes from outside the cluster to services within the cluster.

> For non-HTTP and HTTPS-based traffic, the LoadBalancer or NodePort service objects must be used.

- Advanced traffic routing can be controlled by Ingress rules.
- In the easiest configuration, Ingress forwards all traffic to one service.
- Paths can be used to forward traffic to multiple services.
- Ingress is a loadbalancer on top of a loadbalancer.

Refe rences:

[Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/)
[Ingress Controllers](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/)

## 5. Know how to configure and use CoreDNS

References:

[Using CoreDNS for Service Discovery](https://kubernetes.io/docs/tasks/administer-cluster/coredns/)

## 6. Choose an appropriate container network interface plugin

### CNI Plugin Options

#### Cilium

Cilium is L7/HTTP aware CNI and can enforce network policies on L3-L7 using an identity-based security model decoupled from the network addressing.(Uses eBPF technology).

#### Flannel

Focuses on network, and is simple and easy way to configure a layer three network fabric designed for Kubernetes.

#### Calico

Calico configures a layer three network that uses the BGP routing protocol to route packets between hosts. Can also integrate with Istio, to interpret and enforce policy for workloads within the cluster at the service mush and network infrastructure layers.



References:

[Network Plugins](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/)